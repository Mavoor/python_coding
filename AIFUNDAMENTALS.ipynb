{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIFUNDAMENTALS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPghtSIga6z3WAFrJGB5/OU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sparkprvn/python_coding/blob/main/AIFUNDAMENTALS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ahi7K7ci_Vg5"
      },
      "outputs": [],
      "source": [
        "# AI FUNDAMENTALS\n",
        "# DATACAMP\n",
        "\n",
        "# Load the test example\n",
        "elephant_image = load_elephant()\n",
        "\n",
        "# Apply the model on the test example\n",
        "test_digit_predictor(elephant_image, 'elephant')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing the model accuracy/performance\n",
        "\n",
        "# Define the model\n",
        "model = LogisticRegression(C=100)\n",
        "\n",
        "# Fit the model\n",
        "model.fit(training_inputs, training_labels)\n",
        "\n",
        "# Check model performance\n",
        "check_performance(model, testing_inputs, testing_labels)"
      ],
      "metadata": {
        "id": "ghZzgrrw_sp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#simple model\n",
        "\n",
        "\n",
        "# Select the model appropriate for the task\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X=X_train, y=y_train)\n",
        "\n",
        "# Generate predictions\n",
        "prediction_results = model.predict(X=X_test) \n",
        "\n",
        "# Test the model\n",
        "evaluate_predictions(y_true=y_test,\n",
        "                     y_pred=prediction_results)"
      ],
      "metadata": {
        "id": "guFxGvKMEJL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calling a simple classification model\n",
        "\n",
        "# Select the model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "zA-qzYRmEQp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing a model on the same dataset used for training gives 97.56 % of accuracy\n",
        "\n",
        "# Model setup\n",
        "model = RandomForestClassifier(n_estimators=5, max_depth=20)\n",
        "\n",
        "# Model fitting\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Testing on training data\n",
        "test_and_show_accuracy(model,\n",
        "                       X_test=X_train, \n",
        "                       y_test=y_train)"
      ],
      "metadata": {
        "id": "T9k69GK-FtJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# giving a test dataset to the same model\n",
        "# Model setup\n",
        "model = RandomForestClassifier(n_estimators=5, max_depth=20)\n",
        "\n",
        "# Model fitting\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Testing on testing data\n",
        "test_and_show_accuracy(model,\n",
        "                       X_test=X_test, \n",
        "                       y_test=y_test)\n",
        "\n",
        "# gives only 79.17% of accuracy"
      ],
      "metadata": {
        "id": "NcTnCdzPF1kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the appropriate method to call the model training procedure\n",
        "linear_model.fit(X=x_train, y=y_train)\n",
        "\n",
        "# Check the \"goodness-of-fit\" of the fitted model\n",
        "check_model_fit(model=linear_model,\n",
        "                x=x_train,\n",
        "                y=y_train)"
      ],
      "metadata": {
        "id": "t6LKJua6f8-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new dataset x2_train with 2nd degree polynomial features.\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "x2_train = poly.fit_transform(x_train)\n",
        "\n",
        "# Fit the linear model using the newly created dataset\n",
        "linear_model.fit(X=x2_train, y=y_train)\n",
        "\n",
        "# Check the \"goodness-of-fit\" of the fitted model  \n",
        "check_model_fit(model=linear_model,\n",
        "                x=x2_train,\n",
        "                y=y_train)"
      ],
      "metadata": {
        "id": "9fEy6o30fynH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add outliers to the blob\n",
        "X_new, outliers = add_outliers(X_raw, outlier_distance=200, n_outliers=5)\n",
        "\n",
        "plot_3d_data(X_new, outliers)  \n",
        "\n",
        "# Extract principal components\n",
        "X_2D, outliers_2D = extract_components(X_new, outliers, n_components=2)\n",
        "\n",
        "# Plot the PCA results\n",
        "plot_2d_data(X_2D, outliers_2D)"
      ],
      "metadata": {
        "id": "uPniee1bi_mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_range = list(range(2, 6))\n",
        "\n",
        "summed_distances = []\n",
        "\n",
        "for k in k_range:    \n",
        "    kmeans.set_params(n_clusters=k).fit(X)\n",
        "    summed_distances.append(kmeans.inertia_)\n",
        "\n",
        "plot_elbow_curve(k_range, summed_distances)"
      ],
      "metadata": {
        "id": "qE0ZluuHjx7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DBSCAN\n",
        "# Set eps to 2\n",
        "eps = 2\n",
        "\n",
        "dbscan.set_params(eps=eps)\n",
        "\n",
        "clusters = dbscan.fit_predict(X)\n",
        "\n",
        "plot_clusters(X, clusters)"
      ],
      "metadata": {
        "id": "BzUJ_v5Bklnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate data comprising of the \"clean\" and \"noisy\" components\n",
        "noisy_data, true_labels = make_fake_data(n_blobs=2, n_inliers=1000, n_outliers=50)\n",
        "\n",
        "# Detect anomalies\n",
        "predicted_anomalies = isolation_forest.fit_predict(noisy_data)\n",
        "    \n",
        "# Plot results    \n",
        "plot_detected_anomalies(noisy_data, true_labels, predicted_anomalies)"
      ],
      "metadata": {
        "id": "nKsVZXJcnXeZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}