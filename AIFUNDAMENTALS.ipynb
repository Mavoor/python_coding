{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIFUNDAMENTALS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNsUMs7DSadCiDbIQ11rpgk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sparkprvn/python_coding/blob/main/AIFUNDAMENTALS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ahi7K7ci_Vg5"
      },
      "outputs": [],
      "source": [
        "# AI FUNDAMENTALS\n",
        "# DATACAMP\n",
        "\n",
        "# Load the test example\n",
        "elephant_image = load_elephant()\n",
        "\n",
        "# Apply the model on the test example\n",
        "test_digit_predictor(elephant_image, 'elephant')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing the model accuracy/performance\n",
        "\n",
        "# Define the model\n",
        "model = LogisticRegression(C=100)\n",
        "\n",
        "# Fit the model\n",
        "model.fit(training_inputs, training_labels)\n",
        "\n",
        "# Check model performance\n",
        "check_performance(model, testing_inputs, testing_labels)"
      ],
      "metadata": {
        "id": "ghZzgrrw_sp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#simple model\n",
        "\n",
        "\n",
        "# Select the model appropriate for the task\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X=X_train, y=y_train)\n",
        "\n",
        "# Generate predictions\n",
        "prediction_results = model.predict(X=X_test) \n",
        "\n",
        "# Test the model\n",
        "evaluate_predictions(y_true=y_test,\n",
        "                     y_pred=prediction_results)"
      ],
      "metadata": {
        "id": "guFxGvKMEJL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calling a simple classification model\n",
        "\n",
        "# Select the model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "zA-qzYRmEQp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing a model on the same dataset used for training gives 97.56 % of accuracy\n",
        "\n",
        "# Model setup\n",
        "model = RandomForestClassifier(n_estimators=5, max_depth=20)\n",
        "\n",
        "# Model fitting\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Testing on training data\n",
        "test_and_show_accuracy(model,\n",
        "                       X_test=X_train, \n",
        "                       y_test=y_train)"
      ],
      "metadata": {
        "id": "T9k69GK-FtJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# giving a test dataset to the same model\n",
        "# Model setup\n",
        "model = RandomForestClassifier(n_estimators=5, max_depth=20)\n",
        "\n",
        "# Model fitting\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Testing on testing data\n",
        "test_and_show_accuracy(model,\n",
        "                       X_test=X_test, \n",
        "                       y_test=y_test)\n",
        "\n",
        "# gives only 79.17% of accuracy"
      ],
      "metadata": {
        "id": "NcTnCdzPF1kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the appropriate method to call the model training procedure\n",
        "linear_model.fit(X=x_train, y=y_train)\n",
        "\n",
        "# Check the \"goodness-of-fit\" of the fitted model\n",
        "check_model_fit(model=linear_model,\n",
        "                x=x_train,\n",
        "                y=y_train)"
      ],
      "metadata": {
        "id": "t6LKJua6f8-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new dataset x2_train with 2nd degree polynomial features.\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "x2_train = poly.fit_transform(x_train)\n",
        "\n",
        "# Fit the linear model using the newly created dataset\n",
        "linear_model.fit(X=x2_train, y=y_train)\n",
        "\n",
        "# Check the \"goodness-of-fit\" of the fitted model  \n",
        "check_model_fit(model=linear_model,\n",
        "                x=x2_train,\n",
        "                y=y_train)"
      ],
      "metadata": {
        "id": "9fEy6o30fynH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add outliers to the blob\n",
        "X_new, outliers = add_outliers(X_raw, outlier_distance=200, n_outliers=5)\n",
        "\n",
        "plot_3d_data(X_new, outliers)  \n",
        "\n",
        "# Extract principal components\n",
        "X_2D, outliers_2D = extract_components(X_new, outliers, n_components=2)\n",
        "\n",
        "# Plot the PCA results\n",
        "plot_2d_data(X_2D, outliers_2D)"
      ],
      "metadata": {
        "id": "uPniee1bi_mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_range = list(range(2, 6))\n",
        "\n",
        "summed_distances = []\n",
        "\n",
        "for k in k_range:    \n",
        "    kmeans.set_params(n_clusters=k).fit(X)\n",
        "    summed_distances.append(kmeans.inertia_)\n",
        "\n",
        "plot_elbow_curve(k_range, summed_distances)"
      ],
      "metadata": {
        "id": "qE0ZluuHjx7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DBSCAN\n",
        "# Set eps to 2\n",
        "eps = 2\n",
        "\n",
        "dbscan.set_params(eps=eps)\n",
        "\n",
        "clusters = dbscan.fit_predict(X)\n",
        "\n",
        "plot_clusters(X, clusters)"
      ],
      "metadata": {
        "id": "BzUJ_v5Bklnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate data comprising of the \"clean\" and \"noisy\" components\n",
        "noisy_data, true_labels = make_fake_data(n_blobs=2, n_inliers=1000, n_outliers=50)\n",
        "\n",
        "# Detect anomalies\n",
        "predicted_anomalies = isolation_forest.fit_predict(noisy_data)\n",
        "    \n",
        "# Plot results    \n",
        "plot_detected_anomalies(noisy_data, true_labels, predicted_anomalies)"
      ],
      "metadata": {
        "id": "nKsVZXJcnXeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Kmeans\n",
        "# Set the number of dimensions to 2\n",
        "dimensionality_reducer = PCA(n_components=2)\n",
        "\n",
        "# Apply dimensionality reduction\n",
        "tweets_reduced = dimensionality_reducer.fit_transform(tweets_matrix)\n",
        "\n",
        "# Configure the clustering model\n",
        "clustering_model = KMeans(n_clusters=2)\n",
        "\n",
        "# Find clusters\n",
        "tweet_clusters = clustering_model.fit_predict(tweets_reduced)\n",
        "\n",
        "# Show the clustering results\n",
        "print_cluster_tweets(tweet_clusters, tweets_raw)"
      ],
      "metadata": {
        "id": "7tKujW-_o0gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your model\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# Divide the data into the training and testing set and train the model\n",
        "X_train, X_test, y_train, y_test = train_test_split(client_data, client_churned)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Generate predictions on the test set\n",
        "predictions_test = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model predictions using metrics appropriate for this problem class\n",
        "print_metrics(target_test=y_test,\n",
        "              predictions=predictions_test, \n",
        "              metrics=['accuracy', 'precision', 'recall'])"
      ],
      "metadata": {
        "id": "EmeuyRRWrfPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Deep learning for classification\n",
        "\n",
        "# Initialize the model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the hidden and the output layer, specify the layer type, number of units and input/output dimensions\n",
        "model.add(Dense(units=8, input_dim=16, activation='relu'))\n",
        "model.add(Dense(units=4, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "rbSwLuZNZcYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = Sequential()\n",
        "\n",
        "# Create your 5-layer network (input specified implicitly with 1st layer)\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), input_shape=(28,28, 1)))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "# Set fitting hyper-parameters and compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "wRFp0fmJA72g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_deep_net(input_shape, n_output_classes, n_kernels=32, kernel_size=(3,3)):\n",
        "    # Initialize the sequential model\n",
        "    model = Sequential()\t\n",
        "    # Add the convolutional layer (containing implicitly the input layer)\n",
        "    model.add(Conv2D(input_shape=input_shape, filters=n_kernels, kernel_size=kernel_size, activation='relu'))\n",
        "    # Add the flattening layer\n",
        "    model.add(Flatten())\t\n",
        "    # Add the fully connected layer\n",
        "    model.add(Dense(n_output_classes, activation='softmax')) \n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "BriUXoNhMEd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_deep_net(model, x_test, y_test):\n",
        "    # Generate the test predictions and evaluate against the ground truth\n",
        "    score = model.evaluate(x=x_test, y=y_test)\n",
        "    # Print the evaluation results in a human readable form\n",
        "    print('Test loss: %.2f' % score[0])\n",
        "    print('Test accuracy: %.2f %%' % (100*score[1]))z"
      ],
      "metadata": {
        "id": "LTFP5LOrMiXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct the Deep Neural Network\n",
        "deep_net = make_deep_net(input_shape=[28, 28, 1],\n",
        "                         n_output_classes=10)\n",
        "\n",
        "# Train the Deep Neural Network\n",
        "deep_net.fit(x=x_train, y=y_train,\n",
        "          \t validation_data=(x_test, y_test),\n",
        "          \t batch_size=128,\n",
        "          \t epochs=3)\n",
        "\n",
        "# Estimate the network performance\n",
        "evaluate_deep_net(deep_net, x=x_test, y=y_test)"
      ],
      "metadata": {
        "id": "QaL3mzRBORRA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}